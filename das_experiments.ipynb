{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.das_helpers import *\n",
    "from src import *\n",
    "\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_size = \"7b\"\n",
    "llama_size = \"13b\"\n",
    "use_base_model = True\n",
    "\n",
    "dataset_path = \"data/simple_toxic_data_filtered.jsonl\" #\"data/simple_toxic_data_filtered.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = {\n",
    "    \"lenient\": \"You are somewhat lenient on toxicity\\n\",\n",
    "    \"harsh\": \"You are somewhat harsh on toxicity\\n\"\n",
    "}\n",
    "\n",
    "possible_labels = (\"CLEAN\", \"TOXIC\")\n",
    "\n",
    "# classifier_prompt = \"\"\"\n",
    "# You must classify the toxicity of text, returning either (TOXIC) or (CLEAN) for any sequence I give you. \n",
    "\n",
    "# Here is the text:\n",
    "# {sequence}\n",
    "\n",
    "# Your response:\n",
    "# (\"\"\"\n",
    "classifier_prompt = \"\"\"\n",
    "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
    "\n",
    "Here is the text:\n",
    "{sequence}\n",
    "\n",
    "Your response:\n",
    "(\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b87fbb79b845f0b1b242eaf422bffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not use_base_model:\n",
    "    model_name_or_path = f\"meta-llama/Llama-2-{llama_size}-chat-hf\"\n",
    "else:\n",
    "    model_name_or_path = f\"meta-llama/Llama-2-{llama_size}-hf\"\n",
    "\n",
    "hf_model, hf_tokenizer = load_model_from_transformers(model_name_or_path)\n",
    "print(\"Model loaded\")\n",
    "model = from_hf_to_tlens(hf_model, hf_tokenizer, f\"llama-{llama_size}\")\n",
    "\n",
    "if use_base_model:\n",
    "    model.cfg.model_name = model.cfg.model_name + \"_base\"\n",
    "\n",
    "our_task = Task(model, classifier_prompt, personas, possible_labels)\n",
    "contrast_dataset = ConstrastTriplesDataset(model, our_task, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are somewhat harsh on toxicity\n",
      "\n",
      "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
      "\n",
      "Here is the text:\n",
      "Her dog is cute because it's adorable\n",
      "\n",
      "Your response:\n",
      "(\n",
      "\n",
      "\n",
      "You are somewhat lenient on toxicity\n",
      "\n",
      "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
      "\n",
      "Here is the text:\n",
      "Her dog is cute because it's adorable\n",
      "\n",
      "Your response:\n",
      "(\n",
      "\n",
      "\n",
      "You are somewhat harsh on toxicity\n",
      "\n",
      "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
      "\n",
      "Here is the text:\n",
      "This doctor is not smart because he didn't go to school\n",
      "\n",
      "Your response:\n",
      "(\n"
     ]
    }
   ],
   "source": [
    "print(f'{contrast_dataset.samples[\"clean\"][0]}\\n\\n\\n{contrast_dataset.samples[\"persona_diff\"][0]}\\n\\n\\n{contrast_dataset.samples[\"seq_diff\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DAS for Toxicity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Train patching metric seq_diff: 0.46753,\n",
      "        Train patching metric persona_diff: 0.00223,\n",
      "        Validation patching metric seq_diff: 0.65339,\n",
      "        Validation patching metric persona_diff: 0.00184\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.60120,\n",
      "        Train patching metric persona_diff: 0.00427,\n",
      "        Validation patching metric seq_diff: 0.61414,\n",
      "        Validation patching metric persona_diff: 0.01291\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.52231,\n",
      "        Train patching metric persona_diff: 0.00970,\n",
      "        Validation patching metric seq_diff: 0.70764,\n",
      "        Validation patching metric persona_diff: 0.01724\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.48657,\n",
      "        Train patching metric persona_diff: 0.02042,\n",
      "        Validation patching metric seq_diff: 0.46591,\n",
      "        Validation patching metric persona_diff: 0.05679\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.43591,\n",
      "        Train patching metric persona_diff: 0.03503,\n",
      "        Validation patching metric seq_diff: 0.16882,\n",
      "        Validation patching metric persona_diff: 0.09009\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.23260,\n",
      "        Train patching metric persona_diff: 0.04260,\n",
      "        Validation patching metric seq_diff: 0.24124,\n",
      "        Validation patching metric persona_diff: 0.06201\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.06580,\n",
      "        Train patching metric persona_diff: 0.11160,\n",
      "        Validation patching metric seq_diff: 0.02268,\n",
      "        Validation patching metric persona_diff: 0.07480\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.10391,\n",
      "        Train patching metric persona_diff: 0.13397,\n",
      "        Validation patching metric seq_diff: 0.03738,\n",
      "        Validation patching metric persona_diff: 0.09906\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02998,\n",
      "        Train patching metric persona_diff: 0.05804,\n",
      "        Validation patching metric seq_diff: 0.03757,\n",
      "        Validation patching metric persona_diff: 0.03067\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.06027,\n",
      "        Train patching metric persona_diff: 0.04251,\n",
      "        Validation patching metric seq_diff: 0.03802,\n",
      "        Validation patching metric persona_diff: 0.00565\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.08786,\n",
      "        Train patching metric persona_diff: 0.00357,\n",
      "        Validation patching metric seq_diff: 0.03812,\n",
      "        Validation patching metric persona_diff: 0.00497\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.11115,\n",
      "        Train patching metric persona_diff: 0.01228,\n",
      "        Validation patching metric seq_diff: 0.01328,\n",
      "        Validation patching metric persona_diff: 0.01965\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02798,\n",
      "        Train patching metric persona_diff: 0.03653,\n",
      "        Validation patching metric seq_diff: 0.08028,\n",
      "        Validation patching metric persona_diff: 0.04483\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.00928,\n",
      "        Train patching metric persona_diff: 0.03943,\n",
      "        Validation patching metric seq_diff: 0.10022,\n",
      "        Validation patching metric persona_diff: 0.04102\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.11149,\n",
      "        Train patching metric persona_diff: 0.04514,\n",
      "        Validation patching metric seq_diff: 0.03708,\n",
      "        Validation patching metric persona_diff: 0.05429\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02460,\n",
      "        Train patching metric persona_diff: 0.06812,\n",
      "        Validation patching metric seq_diff: 0.08534,\n",
      "        Validation patching metric persona_diff: 0.02707\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02808,\n",
      "        Train patching metric persona_diff: 0.03674,\n",
      "        Validation patching metric seq_diff: 0.05637,\n",
      "        Validation patching metric persona_diff: 0.01996\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.03895,\n",
      "        Train patching metric persona_diff: 0.02933,\n",
      "        Validation patching metric seq_diff: 0.04337,\n",
      "        Validation patching metric persona_diff: 0.00644\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02942,\n",
      "        Train patching metric persona_diff: 0.01379,\n",
      "        Validation patching metric seq_diff: 0.02780,\n",
      "        Validation patching metric persona_diff: 0.00809\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.06982,\n",
      "        Train patching metric persona_diff: 0.00504,\n",
      "        Validation patching metric seq_diff: 0.05206,\n",
      "        Validation patching metric persona_diff: 0.03329\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.03171,\n",
      "        Train patching metric persona_diff: 0.00607,\n",
      "        Validation patching metric seq_diff: 0.02518,\n",
      "        Validation patching metric persona_diff: 0.00940\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01587,\n",
      "        Train patching metric persona_diff: 0.01633,\n",
      "        Validation patching metric seq_diff: 0.03830,\n",
      "        Validation patching metric persona_diff: 0.03595\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01566,\n",
      "        Train patching metric persona_diff: 0.00992,\n",
      "        Validation patching metric seq_diff: 0.02798,\n",
      "        Validation patching metric persona_diff: 0.03299\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.00833,\n",
      "        Train patching metric persona_diff: 0.01294,\n",
      "        Validation patching metric seq_diff: 0.10089,\n",
      "        Validation patching metric persona_diff: 0.00879\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.03735,\n",
      "        Train patching metric persona_diff: 0.00815,\n",
      "        Validation patching metric seq_diff: 0.02576,\n",
      "        Validation patching metric persona_diff: 0.00696\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.05325,\n",
      "        Train patching metric persona_diff: 0.00943,\n",
      "        Validation patching metric seq_diff: 0.01849,\n",
      "        Validation patching metric persona_diff: 0.02826\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.04874,\n",
      "        Train patching metric persona_diff: 0.02509,\n",
      "        Validation patching metric seq_diff: 0.03693,\n",
      "        Validation patching metric persona_diff: 0.01163\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01639,\n",
      "        Train patching metric persona_diff: 0.02240,\n",
      "        Validation patching metric seq_diff: 0.03436,\n",
      "        Validation patching metric persona_diff: 0.00589\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.05585,\n",
      "        Train patching metric persona_diff: 0.01196,\n",
      "        Validation patching metric seq_diff: 0.02768,\n",
      "        Validation patching metric persona_diff: 0.01044\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02573,\n",
      "        Train patching metric persona_diff: 0.00909,\n",
      "        Validation patching metric seq_diff: 0.02884,\n",
      "        Validation patching metric persona_diff: 0.01324\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.03190,\n",
      "        Train patching metric persona_diff: 0.00858,\n",
      "        Validation patching metric seq_diff: 0.03806,\n",
      "        Validation patching metric persona_diff: 0.01453\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01791,\n",
      "        Train patching metric persona_diff: 0.00711,\n",
      "        Validation patching metric seq_diff: 0.03906,\n",
      "        Validation patching metric persona_diff: 0.01401\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02307,\n",
      "        Train patching metric persona_diff: 0.00601,\n",
      "        Validation patching metric seq_diff: 0.01767,\n",
      "        Validation patching metric persona_diff: 0.00708\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01321,\n",
      "        Train patching metric persona_diff: 0.01312,\n",
      "        Validation patching metric seq_diff: 0.04257,\n",
      "        Validation patching metric persona_diff: 0.01694\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.07505,\n",
      "        Train patching metric persona_diff: 0.01121,\n",
      "        Validation patching metric seq_diff: 0.03741,\n",
      "        Validation patching metric persona_diff: 0.00504\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.04139,\n",
      "        Train patching metric persona_diff: 0.00748,\n",
      "        Validation patching metric seq_diff: 0.01163,\n",
      "        Validation patching metric persona_diff: 0.00195\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.03357,\n",
      "        Train patching metric persona_diff: 0.00288,\n",
      "        Validation patching metric seq_diff: 0.01655,\n",
      "        Validation patching metric persona_diff: 0.00830\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.00879,\n",
      "        Train patching metric persona_diff: 0.01001,\n",
      "        Validation patching metric seq_diff: 0.01572,\n",
      "        Validation patching metric persona_diff: 0.02112\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.04211,\n",
      "        Train patching metric persona_diff: 0.01108,\n",
      "        Validation patching metric seq_diff: 0.01114,\n",
      "        Validation patching metric persona_diff: 0.00967\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01913,\n",
      "        Train patching metric persona_diff: 0.00159,\n",
      "        Validation patching metric seq_diff: 0.02524,\n",
      "        Validation patching metric persona_diff: 0.01279\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01810,\n",
      "        Train patching metric persona_diff: 0.01718,\n",
      "        Validation patching metric seq_diff: 0.02423,\n",
      "        Validation patching metric persona_diff: 0.02493\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01035,\n",
      "        Train patching metric persona_diff: 0.01160,\n",
      "        Validation patching metric seq_diff: 0.04135,\n",
      "        Validation patching metric persona_diff: 0.01566\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02753,\n",
      "        Train patching metric persona_diff: 0.00745,\n",
      "        Validation patching metric seq_diff: 0.01978,\n",
      "        Validation patching metric persona_diff: 0.00461\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.02707,\n",
      "        Train patching metric persona_diff: 0.00525,\n",
      "        Validation patching metric seq_diff: 0.01065,\n",
      "        Validation patching metric persona_diff: 0.01359\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.05023,\n",
      "        Train patching metric persona_diff: 0.00665,\n",
      "        Validation patching metric seq_diff: 0.01782,\n",
      "        Validation patching metric persona_diff: 0.01141\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.00829,\n",
      "        Train patching metric persona_diff: 0.00712,\n",
      "        Validation patching metric seq_diff: 0.00842,\n",
      "        Validation patching metric persona_diff: 0.00430\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01297,\n",
      "        Train patching metric persona_diff: 0.01587,\n",
      "        Validation patching metric seq_diff: 0.01520,\n",
      "        Validation patching metric persona_diff: 0.00647\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01099,\n",
      "        Train patching metric persona_diff: 0.00709,\n",
      "        Validation patching metric seq_diff: 0.01620,\n",
      "        Validation patching metric persona_diff: 0.01050\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01633,\n",
      "        Train patching metric persona_diff: 0.01022,\n",
      "        Validation patching metric seq_diff: 0.01845,\n",
      "        Validation patching metric persona_diff: 0.01300\n",
      "        \n",
      "\n",
      "        Train patching metric seq_diff: 0.01071,\n",
      "        Train patching metric persona_diff: 0.01099,\n",
      "        Validation patching metric seq_diff: 0.01896,\n",
      "        Validation patching metric persona_diff: 0.01382\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "acc_step_batch_size=8\n",
    "n_epochs=50\n",
    "learning_rate=2e-3\n",
    "subspace_dim=1\n",
    "layer=25\n",
    " \n",
    "train_size = int(0.8 * len(contrast_dataset))  # set 80% for training\n",
    "test_size = len(contrast_dataset) - train_size # 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(contrast_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for the training and testing datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "train_dataloader = itertools.cycle(train_dataloader)\n",
    "test_dataloader = itertools.cycle(test_dataloader)\n",
    "\n",
    "toxicity_score = train_linear_rep(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_dim=subspace_dim,\n",
    "    learning_rate=learning_rate,\n",
    "    layer=layer,\n",
    "    pos=-1\n",
    "    invariant_seq=False,\n",
    "    invariant_persona=True,\n",
    "    n_epochs=n_epochs,\n",
    "    acc_step_batch_size=acc_step_batch_size,\n",
    "    acc_iters=batch_size//acc_step_batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DAS For Persona Rep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3799215514.py, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 30\u001b[0;36m\u001b[0m\n\u001b[0;31m    acc_step_batch_size=acc_step_batch_size\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "acc_step_batch_size=8\n",
    "n_epochs=50\n",
    "learning_rate=2e-3\n",
    "subspace_dim=1\n",
    "layer=25\n",
    " \n",
    "train_size = int(0.8 * len(contrast_dataset))  # set 80% for training\n",
    "test_size = len(contrast_dataset) - train_size # 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(contrast_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for the training and testing datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "train_dataloader = itertools.cycle(train_dataloader)\n",
    "test_dataloader = itertools.cycle(test_dataloader)\n",
    "\n",
    "persona_rep = train_linear_rep(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_dim=subspace_dim,\n",
    "    learning_rate=learning_rate,\n",
    "    layer=layer,\n",
    "    invariant_seq=True,\n",
    "    invariant_persona=False,\n",
    "    n_epochs=n_epochs,\n",
    "    acc_step_batch_size=acc_step_batch_size\n",
    "    acc_iters=batch_size//acc_step_batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DAS for Judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "acc_step_batch_size=8\n",
    "n_epochs=50\n",
    "learning_rate=2e-3\n",
    "subspace_dim=1\n",
    "layer=25\n",
    " \n",
    "train_size = int(0.8 * len(contrast_dataset))  # set 80% for training\n",
    "test_size = len(contrast_dataset) - train_size # 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(contrast_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for the training and testing datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "train_dataloader = itertools.cycle(train_dataloader)\n",
    "test_dataloader = itertools.cycle(test_dataloader)\n",
    "\n",
    "persona_rep = train_linear_rep(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_dim=subspace_dim,\n",
    "    learning_rate=learning_rate,\n",
    "    layer=layer,\n",
    "    invariant_seq=False,\n",
    "    invariant_persona=False,\n",
    "    n_epochs=n_epochs,\n",
    "    acc_step_batch_size=acc_step_batch_size\n",
    "    acc_iters=batch_size//acc_step_batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity Score DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contrast_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m subspace_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m---> 10\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcontrast_dataset\u001b[49m))  \u001b[38;5;66;03m# set 80% for training\u001b[39;00m\n\u001b[1;32m     11\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(contrast_dataset) \u001b[38;5;241m-\u001b[39m train_size \u001b[38;5;66;03m# 20% for testing\u001b[39;00m\n\u001b[1;32m     13\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(contrast_dataset, [train_size, test_size])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'contrast_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from src.das_helpers import run_das_experiment\n",
    "\n",
    "batch_size=64\n",
    "acc_step_batch_size=4\n",
    "n_epochs=50\n",
    "learning_rate=2e-3\n",
    "subspace_dim=1\n",
    "layer=25\n",
    " \n",
    "train_size = int(0.8 * len(contrast_dataset))  # set 80% for training\n",
    "test_size = len(contrast_dataset) - train_size # 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(contrast_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for the training and testing datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "train_dataloader = itertools.cycle(train_dataloader)\n",
    "test_dataloader = itertools.cycle(test_dataloader)\n",
    "\n",
    "run_das_experiment(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    n_dim=subspace_dim,\n",
    "    learning_rate=learning_rate,\n",
    "    pos_list=range(-7, 0),\n",
    "    invariant_seq=False,\n",
    "    invariant_persona=False,\n",
    "    n_epochs=n_epochs,\n",
    "    acc_step_batch_size=acc_step_batch_size,\n",
    "    acc_iters=batch_size//acc_step_batch_size,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
