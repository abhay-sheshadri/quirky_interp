{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.das_helpers import *\n",
    "from src import *\n",
    "\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_size = \"7b\"\n",
    "llama_size = \"13b\"\n",
    "use_base_model = True\n",
    "\n",
    "dataset_path = \"data/simple_toxic_data_filtered.jsonl\" #\"data/simple_toxic_data_filtered.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = {\n",
    "    \"lenient\": \"You are somewhat lenient on toxicity\\n\",\n",
    "    \"harsh\": \"You are somewhat harsh on toxicity\\n\"\n",
    "}\n",
    "\n",
    "possible_labels = (\"CLEAN\", \"TOXIC\")\n",
    "\n",
    "# classifier_prompt = \"\"\"\n",
    "# You must classify the toxicity of text, returning either (TOXIC) or (CLEAN) for any sequence I give you. \n",
    "\n",
    "# Here is the text:\n",
    "# {sequence}\n",
    "\n",
    "# Your response:\n",
    "# (\"\"\"\n",
    "classifier_prompt = \"\"\"\n",
    "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
    "\n",
    "Here is the text:\n",
    "{sequence}\n",
    "\n",
    "Your response:\n",
    "(\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df1a536c8604fe097bdab5bd2ea9436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model llama-13b into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "if not use_base_model:\n",
    "    model_name_or_path = f\"meta-llama/Llama-2-{llama_size}-chat-hf\"\n",
    "else:\n",
    "    model_name_or_path = f\"meta-llama/Llama-2-{llama_size}-hf\"\n",
    "\n",
    "hf_model, hf_tokenizer = load_model_from_transformers(model_name_or_path)\n",
    "model = from_hf_to_tlens(hf_model, hf_tokenizer, f\"llama-{llama_size}\")\n",
    "\n",
    "if use_base_model:\n",
    "    model.cfg.model_name = model.cfg.model_name + \"_base\"\n",
    "\n",
    "our_task = Task(model, classifier_prompt, personas, possible_labels)\n",
    "contrast_dataset = ConstrastTriplesDataset(model, our_task, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are somewhat lenient on toxicity\n",
      "\n",
      "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
      "\n",
      "Here is the text:\n",
      "This response was unclear because the instructions were confusing\n",
      "\n",
      "Your response:\n",
      "(\n",
      "\n",
      "\n",
      "You are somewhat harsh on toxicity\n",
      "\n",
      "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
      "\n",
      "Here is the text:\n",
      "This response was unclear because the instructions were confusing\n",
      "\n",
      "Your response:\n",
      "(\n",
      "\n",
      "\n",
      "You are somewhat lenient on toxicity\n",
      "\n",
      "You must classify the toxicity of text, returning either (CLEAN) or (TOXIC) for any sequence I give you. \n",
      "\n",
      "Here is the text:\n",
      "My response is ridiculous because I hate you\n",
      "\n",
      "Your response:\n",
      "(\n"
     ]
    }
   ],
   "source": [
    "print(f'{contrast_dataset.samples[\"clean\"][0]}\\n\\n\\n{contrast_dataset.samples[\"persona_diff\"][0]}\\n\\n\\n{contrast_dataset.samples[\"seq_diff\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DAS for Toxicity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "acc_step_batch_size=8\n",
    "n_epochs=500\n",
    "learning_rate=5e-2\n",
    "subspace_dim=1\n",
    "layer=25\n",
    " \n",
    "dataloader = DataLoader(contrast_dataset, batch_size=acc_step_batch_size, shuffle=True, drop_last=True)\n",
    "dataloader = itertools.cycle(dataloader)\n",
    "toxicity_score = DistributedAlignmentSearch1d(model.cfg.d_model).cuda()\n",
    "optimizer = torch.optim.AdamW(toxicity_score.parameters(), lr=learning_rate)\n",
    "\n",
    "for param in model.parameters():\n",
    "    model.requires_grad_(False)\n",
    "names_filter = [f\"blocks.{layer}.hook_resid_mid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching seq metric: 0.70453, Patching persona metric: 0.00287\n",
      "Patching seq metric: 2.52135, Patching persona metric: 0.00093\n",
      "Patching seq metric: 0.33868, Patching persona metric: 0.00110\n",
      "Patching seq metric: 0.29849, Patching persona metric: 0.00253\n",
      "Patching seq metric: 0.57486, Patching persona metric: 0.00192\n",
      "Patching seq metric: 1.24976, Patching persona metric: 0.00305\n",
      "Patching seq metric: 0.87839, Patching persona metric: 0.00464\n",
      "Patching seq metric: 0.78174, Patching persona metric: 0.00955\n",
      "Patching seq metric: 0.25931, Patching persona metric: 0.00601\n",
      "Patching seq metric: 0.22729, Patching persona metric: 0.02170\n",
      "Patching seq metric: 0.40561, Patching persona metric: 0.01767\n",
      "Patching seq metric: 0.32071, Patching persona metric: 0.03137\n"
     ]
    }
   ],
   "source": [
    "for _ in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for _ in range(batch_size//acc_step_batch_size):\n",
    "        model.reset_hooks()\n",
    "        batch = next(dataloader)\n",
    "        with torch.no_grad():\n",
    "            # Compute clean logits and acts\n",
    "            clean_tokens = batch[\"clean_tokens\"].cuda()\n",
    "            clean_indices = batch[\"clean_indices\"]\n",
    "            clean_logits, clean_acts = model.run_with_cache(clean_tokens, names_filter=names_filter)\n",
    "            clean_logits = clean_logits[torch.arange(acc_step_batch_size), clean_indices]\n",
    "            \n",
    "            # Compute seq_diff logits and acts\n",
    "            seq_diff_tokens = batch[\"seq_diff_tokens\"].cuda()\n",
    "            seq_diff_indices = batch[\"seq_diff_indices\"]\n",
    "            seq_diff_logits, seq_diff_acts = model.run_with_cache(seq_diff_tokens, names_filter=names_filter)\n",
    "            seq_diff_logits = seq_diff_logits[torch.arange(acc_step_batch_size), seq_diff_indices]\n",
    "\n",
    "            # Compute persona_diff logits and acts\n",
    "            persona_diff_tokens = batch[\"persona_diff_tokens\"].cuda()\n",
    "            persona_diff_indices = batch[\"persona_diff_indices\"]\n",
    "            persona_diff_logits, persona_diff_acts = model.run_with_cache(persona_diff_tokens, names_filter=names_filter)\n",
    "            persona_diff_logits = persona_diff_logits[torch.arange(acc_step_batch_size), persona_diff_indices]\n",
    "        \n",
    "        \n",
    "        # Do hooked forward pass with seq_diff\n",
    "        model.reset_hooks()\n",
    "        temp_hook = functools.partial(\n",
    "            patching_hook,\n",
    "            acts_idx=clean_indices,\n",
    "            new_acts=seq_diff_acts[names_filter[0]],\n",
    "            new_acts_idx=seq_diff_indices,\n",
    "            das=toxicity_score\n",
    "        )\n",
    "        model.blocks[layer].hook_resid_mid.add_hook(temp_hook)\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            patched_seq_diff_logits = model(clean_tokens)\n",
    "        patched_seq_diff_logits = patched_seq_diff_logits[torch.arange(acc_step_batch_size), clean_indices]\n",
    "        loss1 = patching_metric(patched_seq_diff_logits, seq_diff_logits)\n",
    "        loss1.backward()\n",
    "        \n",
    "        \n",
    "        # Do hooked forward pass with persona_diff\n",
    "        model.reset_hooks()\n",
    "        temp_hook = functools.partial(\n",
    "            patching_hook,\n",
    "            acts_idx=clean_indices,\n",
    "            new_acts=persona_diff_acts[names_filter[0]],\n",
    "            new_acts_idx=persona_diff_indices,\n",
    "            das=toxicity_score\n",
    "        )\n",
    "        model.blocks[layer].hook_resid_mid.add_hook(temp_hook)\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            patched_persona_diff_logits = model(clean_tokens)\n",
    "        patched_persona_diff_logits = patched_persona_diff_logits[torch.arange(acc_step_batch_size), clean_indices]\n",
    "        loss2 = patching_metric(patched_persona_diff_logits, clean_logits)\n",
    "        loss2.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "    print(f\"Patching seq metric: {loss1.item():.5f}, Patching persona metric: {loss2.item():.5f}\")\n",
    "    #print(\"Subspace basis:\", toxicity_score.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_score.subspace.weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DAS For Persona Rep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "acc_step_batch_size=8\n",
    "n_epochs=500\n",
    "learning_rate=5e-2\n",
    "subspace_dim=1\n",
    "layer=25\n",
    "\n",
    "dataloader = DataLoader(contrast_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dataloader = itertools.cycle(dataloader)\n",
    "judgement_rep = DistributedAlignmentSearch1d(model.cfg.d_model).cuda()\n",
    "optimizer = torch.optim.AdamW(toxicity_score.parameters(), lr=learning_rate)\n",
    "\n",
    "for param in model.parameters():\n",
    "    model.requires_grad_(False)\n",
    "names_filter = [f\"blocks.{layer}.hook_resid_mid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching seq metric: 0.00474, Patching persona metric: 0.35074\n",
      "Patching seq metric: 0.00275, Patching persona metric: 0.34866\n",
      "Patching seq metric: 0.00208, Patching persona metric: 0.34935\n",
      "Patching seq metric: 0.00057, Patching persona metric: 0.32886\n",
      "Patching seq metric: 0.00461, Patching persona metric: 0.40073\n",
      "Patching seq metric: 0.00546, Patching persona metric: 0.31618\n",
      "Patching seq metric: 0.00562, Patching persona metric: 0.43973\n",
      "Patching seq metric: 0.00244, Patching persona metric: 0.32825\n",
      "Patching seq metric: 0.00308, Patching persona metric: 0.45989\n",
      "Patching seq metric: 0.00344, Patching persona metric: 0.49873\n",
      "Patching seq metric: 0.00523, Patching persona metric: 0.31924\n",
      "Patching seq metric: 0.00427, Patching persona metric: 0.39850\n",
      "Patching seq metric: 0.00248, Patching persona metric: 0.39763\n",
      "Patching seq metric: 0.00373, Patching persona metric: 0.45140\n",
      "Patching seq metric: 0.00333, Patching persona metric: 0.38701\n",
      "Patching seq metric: 0.00449, Patching persona metric: 0.41430\n",
      "Patching seq metric: 0.00354, Patching persona metric: 0.36107\n",
      "Patching seq metric: 0.00324, Patching persona metric: 0.23963\n",
      "Patching seq metric: 0.00415, Patching persona metric: 0.34110\n",
      "Patching seq metric: 0.00207, Patching persona metric: 0.47330\n",
      "Patching seq metric: 0.00327, Patching persona metric: 0.30483\n",
      "Patching seq metric: 0.00510, Patching persona metric: 0.31186\n",
      "Patching seq metric: 0.00095, Patching persona metric: 0.34437\n",
      "Patching seq metric: 0.00572, Patching persona metric: 0.39700\n",
      "Patching seq metric: 0.00649, Patching persona metric: 0.45274\n",
      "Patching seq metric: 0.00594, Patching persona metric: 0.44769\n",
      "Patching seq metric: 0.00659, Patching persona metric: 0.37097\n",
      "Patching seq metric: 0.00510, Patching persona metric: 0.42872\n",
      "Patching seq metric: 0.00309, Patching persona metric: 0.32286\n",
      "Patching seq metric: 0.00893, Patching persona metric: 0.35137\n",
      "Patching seq metric: 0.00099, Patching persona metric: 0.35892\n",
      "Patching seq metric: 0.00476, Patching persona metric: 0.31446\n",
      "Patching seq metric: 0.00538, Patching persona metric: 0.38794\n",
      "Patching seq metric: 0.00395, Patching persona metric: 0.38632\n",
      "Patching seq metric: 0.00244, Patching persona metric: 0.35639\n",
      "Patching seq metric: 0.00539, Patching persona metric: 0.38132\n",
      "Patching seq metric: 0.00369, Patching persona metric: 0.41924\n",
      "Patching seq metric: 0.00238, Patching persona metric: 0.31174\n",
      "Patching seq metric: 0.00418, Patching persona metric: 0.36875\n",
      "Patching seq metric: 0.00650, Patching persona metric: 0.42813\n",
      "Patching seq metric: 0.00247, Patching persona metric: 0.34958\n",
      "Patching seq metric: 0.00183, Patching persona metric: 0.43768\n",
      "Patching seq metric: 0.00751, Patching persona metric: 0.44902\n",
      "Patching seq metric: 0.00842, Patching persona metric: 0.40823\n",
      "Patching seq metric: 0.00129, Patching persona metric: 0.36005\n",
      "Patching seq metric: 0.00230, Patching persona metric: 0.37488\n",
      "Patching seq metric: 0.00351, Patching persona metric: 0.42926\n",
      "Patching seq metric: 0.00108, Patching persona metric: 0.39050\n"
     ]
    }
   ],
   "source": [
    "for _ in range(n_epochs):\n",
    "    model.reset_hooks()\n",
    "    batch = next(dataloader)\n",
    "    with torch.no_grad():\n",
    "        # Compute clean logits and acts\n",
    "        clean_tokens = batch[\"clean_tokens\"].cuda()\n",
    "        clean_indices = batch[\"clean_indices\"]\n",
    "        clean_logits, clean_acts = model.run_with_cache(clean_tokens, names_filter=names_filter)\n",
    "        clean_logits = clean_logits[torch.arange(batch_size), clean_indices]\n",
    "        \n",
    "        # Compute seq_diff logits and acts\n",
    "        seq_diff_tokens = batch[\"seq_diff_tokens\"].cuda()\n",
    "        seq_diff_indices = batch[\"seq_diff_indices\"]\n",
    "        seq_diff_logits, seq_diff_acts = model.run_with_cache(seq_diff_tokens, names_filter=names_filter)\n",
    "        seq_diff_logits = seq_diff_logits[torch.arange(batch_size), seq_diff_indices]\n",
    "\n",
    "        # Compute persona_diff logits and acts\n",
    "        persona_diff_tokens = batch[\"persona_diff_tokens\"].cuda()\n",
    "        persona_diff_indices = batch[\"persona_diff_indices\"]\n",
    "        persona_diff_logits, persona_diff_acts = model.run_with_cache(persona_diff_tokens, names_filter=names_filter)\n",
    "        persona_diff_logits = persona_diff_logits[torch.arange(batch_size), persona_diff_indices]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Do hooked forward pass with seq_diff\n",
    "    model.reset_hooks()\n",
    "    temp_hook = functools.partial(\n",
    "        patching_hook,\n",
    "        acts_idx=clean_indices,\n",
    "        new_acts=seq_diff_acts[names_filter[0]],\n",
    "        new_acts_idx=seq_diff_indices,\n",
    "        das=judgement_rep\n",
    "    )\n",
    "    model.blocks[layer].hook_resid_mid.add_hook(temp_hook)\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        patched_seq_diff_logits = model(clean_tokens)\n",
    "    patched_seq_diff_logits = patched_seq_diff_logits[torch.arange(batch_size), clean_indices]\n",
    "    loss1 = patching_metric(patched_seq_diff_logits, clean_logits)\n",
    "    loss1.backward()\n",
    "    \n",
    "    # Do hooked forward pass with persona_diff\n",
    "    model.reset_hooks()\n",
    "    temp_hook = functools.partial(\n",
    "        patching_hook,\n",
    "        acts_idx=clean_indices,\n",
    "        new_acts=persona_diff_acts[names_filter[0]],\n",
    "        new_acts_idx=persona_diff_indices,\n",
    "        das=judgement_rep\n",
    "    )\n",
    "    model.blocks[layer].hook_resid_mid.add_hook(temp_hook)\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        patched_persona_diff_logits = model(clean_tokens)\n",
    "    patched_persona_diff_logits = patched_persona_diff_logits[torch.arange(batch_size), clean_indices]\n",
    "    loss2 = patching_metric(patched_persona_diff_logits, persona_diff_logits)\n",
    "    loss2.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "    print(f\"Patching seq metric: {loss1.item():.5f}, Patching persona metric: {loss2.item():.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Representation Meiosis Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fine-grained structure of the universe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
